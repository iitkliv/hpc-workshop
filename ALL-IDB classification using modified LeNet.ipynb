{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified LeNet for ALL-IDB Classification\n",
    "\n",
    "### Dataset used:- [ALL-IDB:Acute Lymphoblastic Leukemia Image Database for Image Processing](https://homes.di.unimi.it/scotti/all/)\n",
    "Follow the instructions provided in the linked website to download the dataset. After downloading, extract the files to the current directory (same folder as your codes). Note that ALL_IDB2 is used in this  tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datapath = 'ALL_IDB2/img/'\n",
    "listing = os.listdir(Datapath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_IDB2 dataset has 260 images in total\n",
    "TrainImages = torch.FloatTensor(200,3,32,32)\n",
    "TrainLabels = torch.LongTensor(200)\n",
    "TestImages = torch.FloatTensor(60,3,32,32)\n",
    "TestLabels = torch.LongTensor(60)\n",
    "\n",
    "# First 200 images are used for training and the remaining 60 for testing\n",
    "img_no = 0\n",
    "for file in listing:\n",
    "    im=Image.open(Datapath + file)\n",
    "    im = im.resize((32,32))\n",
    "    im = np.array(im)   \n",
    "    if img_no < 200:\n",
    "        TrainImages[img_no] = torch.from_numpy(im).transpose(0,2).unsqueeze(0)\n",
    "        TrainLabels[img_no] = int(listing[img_no][6:7])\n",
    "    else:\n",
    "        TestImages[img_no - 200] = torch.from_numpy(im).transpose(0,2).unsqueeze(0)\n",
    "        TestLabels[img_no - 200] = int(listing[img_no][6:7])\n",
    "    img_no = img_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainImages.size())\n",
    "print(TrainLabels.size())\n",
    "print(TestImages.size())\n",
    "print(TestLabels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pytorch dataset from the feature matices\n",
    "trainDataset = TensorDataset(TrainImages, TrainLabels)\n",
    "testDataset = TensorDataset(TestImages, TestLabels)\n",
    "# Creating dataloader\n",
    "BatchSize = 64\n",
    "trainLoader = DataLoader(trainDataset, batch_size=BatchSize, shuffle=True,num_workers=4, pin_memory=True)\n",
    "testLoader = DataLoader(testDataset, batch_size=BatchSize, shuffle=True,num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.log_softmax(self.fc3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LeNet()\n",
    "print(net)\n",
    "\n",
    "if use_gpu:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-Likelihood\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9) # Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 5\n",
    "trainLoss = []\n",
    "testAcc = []\n",
    "start = time.time()\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0    \n",
    "    net.train(True) # For training\n",
    "    for data in trainLoader:\n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.float().cuda()), \\\n",
    "                Variable(labels.long().cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labelslong()) \n",
    "        inputs = inputs/255.0\n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Feed-forward input data through the network\n",
    "        outputs = net(inputs)\n",
    "        # Compute loss/error\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.item()\n",
    "    avgTrainLoss = runningLoss/200\n",
    "    trainLoss.append(avgTrainLoss)\n",
    "    \n",
    "    # Evaluating performance on test set for each epoch\n",
    "    net.train(False) # For testing\n",
    "    inputs = TestImages/255\n",
    "    if use_gpu:\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.cpu()\n",
    "    else:\n",
    "        inputs = Variable(inputs)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total += TestLabels.size(0)\n",
    "    correct += (predicted == TestLabels).sum()\n",
    "    avgTestAcc = correct.numpy()/60.0\n",
    "    testAcc.append(avgTestAcc)\n",
    "        \n",
    "    # Plotting training loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainLoss,'r-',label='train')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Training loss')   \n",
    "    # Plotting testing accuracy vs Epochs\n",
    "    fig2 = plt.figure(2)        \n",
    "    plt.plot(range(epoch+1),testAcc,'g-',label='test')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Testing accuracy')    \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Testing Acc: {:.3f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTrainLoss,avgTestAcc*100,epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
